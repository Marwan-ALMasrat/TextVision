{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur6msxX-itwx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Embedding, LSTM, Dense, Dropout,\n",
        "                                   BatchNormalization, GlobalMaxPooling1D)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔧 إعداد GPU...\")\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(f\"✅ GPU متاح: {physical_devices[0]}\")\n",
        "else:\n",
        "    print(\"💻 تشغيل على CPU\")\n"
      ],
      "metadata": {
        "id": "7b4mnfkbi_21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# إنشاء مجلد النماذج\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "print(\"📁 قراءة البيانات...\")\n",
        "data_train = pd.read_csv('train.csv')\n",
        "data_test = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"📊 حجم التدريب: {data_train.shape}\")\n",
        "print(f\"📊 حجم الاختبار: {data_test.shape}\")"
      ],
      "metadata": {
        "id": "EQm8rjFGjHVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"📈 توزيع الفئات:\")\n",
        "class_counts = data_train['Class Index'].value_counts().sort_index()\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "id": "V9qret_1jL7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🧹 تنظيف البيانات...\")\n",
        "data_train['Title'] = data_train['Title'].fillna('').astype(str)\n",
        "data_train['Description'] = data_train['Description'].fillna('').astype(str)\n",
        "data_test['Title'] = data_test['Title'].fillna('').astype(str)\n",
        "data_test['Description'] = data_test['Description'].fillna('').astype(str)\n"
      ],
      "metadata": {
        "id": "VwUndxFWjPO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# دمج النصوص\n",
        "texts_train = (data_train['Title'] + ' ' + data_train['Description']).tolist()\n",
        "texts_test = (data_test['Title'] + ' ' + data_test['Description']).tolist()\n",
        "\n",
        "print(f\"📝 عينة من النصوص: {texts_train[0][:100]}...\")"
      ],
      "metadata": {
        "id": "zsj6lpjpjSxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# معاملات محسنة للسرعة والدقة\n",
        "max_words = 20000  # تقليل القاموس للسرعة\n",
        "max_len = 100      # تقليل طول الجملة للسرعة\n",
        "batch_size = 128   # زيادة batch size للسرعة\n",
        "\n",
        "print(\"🔤 بناء القاموس...\")\n",
        "tokenizer = Tokenizer(\n",
        "    num_words=max_words,\n",
        "    oov_token=\"<OOV>\",\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        ")\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "print(f\"📖 حجم القاموس: {min(len(tokenizer.word_index), max_words)}\")\n"
      ],
      "metadata": {
        "id": "-DFs8vQKjWSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تحويل النصوص\n",
        "X_train_seq = tokenizer.texts_to_sequences(texts_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "print(f\"✂️ شكل البيانات: {X_train_pad.shape}\")\n"
      ],
      "metadata": {
        "id": "g5O-gnXEjYra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# معالجة التصنيفات\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(data_train['Class Index'])\n",
        "y_train_cat = to_categorical(y_train)\n",
        "num_classes = y_train_cat.shape[1]\n",
        "\n",
        "print(f\"🏷️ عدد الفئات: {num_classes}\")\n",
        "print(f\"🏷️ أسماء الفئات: {label_encoder.classes_}\")\n"
      ],
      "metadata": {
        "id": "KaU4L1KLjapP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تقسيم البيانات\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train_pad, y_train_cat,\n",
        "    test_size=0.15,  # تقليل validation set\n",
        "    random_state=42,\n",
        "    stratify=y_train_cat\n",
        ")\n",
        "\n",
        "print(f\"🔄 التدريب: {X_train_split.shape}, التحقق: {X_val.shape}\")\n",
        "\n",
        "print(\"🏗️ بناء النموذج المبسط...\")\n"
      ],
      "metadata": {
        "id": "KO5N8w7fjcIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نموذج مبسط وسريع\n",
        "model = Sequential([\n",
        "    # Embedding بسيط\n",
        "    Embedding(\n",
        "        input_dim=max_words,\n",
        "        output_dim=128,  # تقليل البعد للسرعة\n",
        "        input_length=max_len,\n",
        "        mask_zero=True  # تجاهل padding\n",
        "    ),"
      ],
      "metadata": {
        "id": "rH0qmU_KjcER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # LSTM واحد فقط\n",
        "    LSTM(64, dropout=0.3, recurrent_dropout=0.3),\n",
        "\n",
        "    # Dense layers بسيطة\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # طبقة الإخراج\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "BlbvonOZjbI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer محسن\n",
        "optimizer = Adam(\n",
        "    learning_rate=0.01,  # learning rate أعلى للبداية السريعة\n",
        "    clipnorm=1.0\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "QdedrMrWjbfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks محسنة\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=3,  # patience أقل\n",
        "        restore_best_weights=True,\n",
        "        mode='max'\n",
        "    ),\n",
        "\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_accuracy',  # مراقبة accuracy بدلاً من loss\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"🚀 بدء التدريب...\")"
      ],
      "metadata": {
        "id": "vc7XQADgkR0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تدريب سريع\n",
        "history = model.fit(\n",
        "    X_train_split, y_train_split,\n",
        "    epochs=15,  # epochs أقل\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "TNip7l5HkVdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# التقييم\n",
        "print(\"📊 تقييم النموذج...\")\n",
        "train_acc = model.evaluate(X_train_split, y_train_split, verbose=0)[1]\n",
        "val_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "\n",
        "print(f\"🎯 دقة التدريب: {train_acc:.4f}\")\n",
        "print(f\"🎯 دقة التحقق: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "f3TSBUZ_kXkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# التنبؤ\n",
        "print(\"🔮 إجراء التنبؤات...\")\n",
        "y_pred = model.predict(X_test_pad, batch_size=batch_size, verbose=1)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n"
      ],
      "metadata": {
        "id": "Iv8xrXEHkbbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# حفظ النماذج\n",
        "print(\"💾 حفظ النماذج...\")\n",
        "model.save('models/lstm_simple.h5')\n",
        "\n",
        "import pickle\n",
        "with open('models/tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open('models/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)"
      ],
      "metadata": {
        "id": "aKYmQEbykbZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# رسم النتائج\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training', linewidth=2)\n",
        "plt.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training', linewidth=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/results.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ اكتمل التدريب!\")"
      ],
      "metadata": {
        "id": "Pn28rYv9kbXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kG_A91BGkbUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3owBM1RkbS5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}